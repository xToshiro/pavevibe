{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4356912-ae30-4052-a228-e97379f46b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      latitude     longitude elevation  speed satellites                time  \\\n",
      "0  -3.74468661  -38.57741007    16.312  0.000         32 2024-04-09 10:14:22   \n",
      "1  -3.74468491  -38.57741068    16.476  0.000         32 2024-04-09 10:14:23   \n",
      "2  -3.74468784  -38.57741192    16.121  0.000         32 2024-04-09 10:14:24   \n",
      "3  -3.74468931  -38.57741166    15.629  0.000         32 2024-04-09 10:14:25   \n",
      "4  -3.74469007  -38.57741203    15.846  0.000         33 2024-04-09 10:14:26   \n",
      "\n",
      "         date      hour  \n",
      "0  2024-04-09  10:14:22  \n",
      "1  2024-04-09  10:14:23  \n",
      "2  2024-04-09  10:14:24  \n",
      "3  2024-04-09  10:14:25  \n",
      "4  2024-04-09  10:14:26  \n"
     ]
    }
   ],
   "source": [
    "from xml.etree import ElementTree as ET\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Caminho para o arquivo GPX fornecido\n",
    "gpx_file_path = '20240409-101422 - Trajeto de teste 1 09_04.gpx'\n",
    "\n",
    "# Caminho para o arquivo data.csv\n",
    "data_csv_path = 'data.csv'\n",
    "\n",
    "# Ler o arquivo GPX\n",
    "with open(gpx_file_path, 'r') as gpx_file:\n",
    "    gpx_tree = ET.parse(gpx_file)\n",
    "    root = gpx_tree.getroot()\n",
    "\n",
    "# Namespace para o arquivo GPX\n",
    "namespace = 'http://www.topografix.com/GPX/1/0'\n",
    "\n",
    "# Encontrar trilhas no arquivo GPX\n",
    "tracks = root.findall(f'{{{namespace}}}trk')\n",
    "\n",
    "# Encontrar segmentos na primeira trilha\n",
    "trkseg = tracks[0].find(f'{{{namespace}}}trkseg')\n",
    "\n",
    "# Extrair pontos de trilha\n",
    "trkpts = trkseg.findall(f'{{{namespace}}}trkpt')\n",
    "\n",
    "# Extrair informações de cada ponto de trilha, incluindo velocidade (speed) e satélites (sat)\n",
    "trkpt_data = []\n",
    "for pt in trkpts:\n",
    "    lat = pt.attrib['lat']\n",
    "    lon = pt.attrib['lon']\n",
    "    ele = pt.find(f'{{{namespace}}}ele').text if pt.find(f'{{{namespace}}}ele') is not None else None\n",
    "    speed = pt.find(f'{{{namespace}}}speed').text if pt.find(f'{{{namespace}}}speed') is not None else None\n",
    "    sat = pt.find(f'{{{namespace}}}sat').text if pt.find(f'{{{namespace}}}sat') is not None else None\n",
    "    time_text = pt.find(f'{{{namespace}}}time').text if pt.find(f'{{{namespace}}}time') is not None else None\n",
    "    time = datetime.strptime(time_text, '%Y-%m-%dT%H:%M:%SZ') if time_text else None\n",
    "    trkpt_data.append({\n",
    "        'latitude': lat,\n",
    "        'longitude': lon,\n",
    "        'elevation': ele,\n",
    "        'speed': speed,\n",
    "        'satellites': sat,\n",
    "        'time': time\n",
    "    })\n",
    "\n",
    "# Converter para DataFrame\n",
    "trkpt_df = pd.DataFrame(trkpt_data)\n",
    "\n",
    "# Diminuir 3 horas da coluna 'time'\n",
    "trkpt_df['time'] = trkpt_df['time'] - pd.Timedelta(hours=3)\n",
    "\n",
    "# Separar a coluna 'time' em 'date' e 'hour'\n",
    "trkpt_df['date'] = trkpt_df['time'].dt.date\n",
    "trkpt_df['hour'] = trkpt_df['time'].dt.time\n",
    "\n",
    "# Exibir as primeiras linhas para verificar\n",
    "print(trkpt_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54d9c2fb-1eb0-44c4-b503-84ca7a154b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jairo\\AppData\\Local\\Temp\\ipykernel_60692\\3562980708.py:8: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data_csv_df['RTCData'] = pd.to_datetime(data_csv_df['RTCData'], errors='coerce', dayfirst=True).dt.date\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ler o arquivo data.csv\n",
    "data_csv_df = pd.read_csv(data_csv_path, sep=',')\n",
    "\n",
    "# Corrigir o nome das colunas, removendo espaços extras\n",
    "data_csv_df.columns = data_csv_df.columns.str.strip()\n",
    "\n",
    "# Converter RTCData e RTCHora para o mesmo formato de trkpt_df, tratando datas e horas inválidas\n",
    "data_csv_df['RTCData'] = pd.to_datetime(data_csv_df['RTCData'], errors='coerce', dayfirst=True).dt.date\n",
    "data_csv_df['RTCHora'] = pd.to_datetime(data_csv_df['RTCHora'], errors='coerce', format='%H:%M:%S').dt.time\n",
    "\n",
    "# Realizar o merge com base em 'RTCData', 'RTCHora' e as colunas 'date', 'hour' de trkpt_df\n",
    "merged_df = pd.merge(data_csv_df, trkpt_df[['latitude', 'longitude', 'elevation', 'date', 'hour', 'speed', 'satellites']],\n",
    "                     left_on=['RTCData', 'RTCHora'], right_on=['date', 'hour'], how='left')\n",
    "\n",
    "\n",
    "# Renomear colunas para corresponder aos nomes especificados\n",
    "merged_df.rename(columns={'latitude': 'LatLogger', 'longitude': 'LongLogger',\n",
    "                          'elevation': 'ElevationLogger', 'date': 'DataLogger', 'hour': 'HoraLogger', 'speed': 'SpeedLogger', 'satellites': 'SatellitesLogger'},\n",
    "                 inplace=True)\n",
    "\n",
    "# Definir o caminho do arquivo de destino\n",
    "caminho_arquivo_csv = 'datacsv2.csv' # Ajuste o caminho conforme necessário\n",
    "# Exportar o DataFrame para um arquivo CSV\n",
    "data_csv_df.to_csv(caminho_arquivo_csv, sep=';', encoding='ISO-8859-1', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bf25420-e81d-4305-9edc-e470a252ee64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      RTCData   RTCHora GPSData GPSHora  Lat  Long  Altgps  Vel  GPSUpdate  \\\n",
       " 0         NaT  00:00:00   0/0/0   0:0:0  NaN   NaN     0.0  0.0          0   \n",
       " 1  2024-04-09  09:52:12   0/0/0   0:0:0  NaN   NaN     0.0  0.0          0   \n",
       " 2  2024-04-09  09:52:12   0/0/0   0:0:0  NaN   NaN     0.0  0.0          0   \n",
       " 3  2024-04-09  09:52:12   0/0/0   0:0:0  NaN   NaN     0.0  0.0          0   \n",
       " 4  2024-04-09  09:52:12   0/0/0   0:0:0  NaN   NaN     0.0  0.0          0   \n",
       " \n",
       "      Ax  ...    Gy    Gz  indiceAmostra  LatLogger  LongLogger  \\\n",
       " 0  0.00  ...  0.00  0.00              0        NaN         NaN   \n",
       " 1  0.01  ...  0.65 -1.65              1        NaN         NaN   \n",
       " 2  0.01  ...  0.95 -1.53              2        NaN         NaN   \n",
       " 3  0.01  ...  0.77 -1.34              3        NaN         NaN   \n",
       " 4  0.01  ...  0.89 -1.46              4        NaN         NaN   \n",
       " \n",
       "    ElevationLogger DataLogger HoraLogger SpeedLogger SatellitesLogger  \n",
       " 0              NaN        NaN        NaN         NaN              NaN  \n",
       " 1              NaN        NaN        NaN         NaN              NaN  \n",
       " 2              NaN        NaN        NaN         NaN              NaN  \n",
       " 3              NaN        NaN        NaN         NaN              NaN  \n",
       " 4              NaN        NaN        NaN         NaN              NaN  \n",
       " \n",
       " [5 rows x 23 columns],\n",
       " (13326, 23))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head(), merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1b3430c-823b-4173-8d41-9932abec1e26",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'gpsMergeData.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m caminho_arquivo_csv \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpsMergeData.csv\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# Ajuste o caminho conforme necessário\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Exportar o DataFrame para um arquivo CSV\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmerged_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcaminho_arquivo_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m;\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mISO-8859-1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:3964\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3953\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3955\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3956\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3957\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3961\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3962\u001b[0m )\n\u001b[1;32m-> 3964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3967\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'gpsMergeData.csv'"
     ]
    }
   ],
   "source": [
    "# Definir o caminho do arquivo de destino\n",
    "caminho_arquivo_csv = 'gpsMergeData.csv' # Ajuste o caminho conforme necessário\n",
    "# Exportar o DataFrame para um arquivo CSV\n",
    "merged_df.to_csv(caminho_arquivo_csv, sep=';', encoding='ISO-8859-1', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e862c3d8-a838-409e-8472-b210ffe35726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows where the column 'DataLogger' has missing values\n",
    "merged_df_cleaned = merged_df.dropna(subset=['DataLogger'])\n",
    "\n",
    "# Display the first few rows of the cleaned DataFrame to confirm the changes\n",
    "merged_df_cleaned.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e0c0b9-678f-418b-8dd1-bd1f20159072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Supondo que o DataFrame 'merged_df' já foi carregado\n",
    "\n",
    "# Criar uma cópia limpa do DataFrame para trabalhar\n",
    "merged_df_cleaned = merged_df.dropna(subset=['DataLogger']).copy()\n",
    "\n",
    "# Converter 'RTCHora' para string\n",
    "merged_df_cleaned['RTCHora'] = merged_df_cleaned['RTCHora'].astype(str)\n",
    "\n",
    "# Adicionar a coluna 'Seconds'\n",
    "merged_df_cleaned['Seconds'] = pd.to_timedelta(merged_df_cleaned['RTCHora']).dt.total_seconds()\n",
    "\n",
    "# Assegurar que 'LatLogger' e 'LongLogger' são numéricos e tratar NaNs\n",
    "merged_df_cleaned['LatLogger'] = pd.to_numeric(merged_df_cleaned['LatLogger'], errors='coerce')\n",
    "merged_df_cleaned['LongLogger'] = pd.to_numeric(merged_df_cleaned['LongLogger'], errors='coerce')\n",
    "\n",
    "# Preencher valores NaN para evitar erros na interpolação\n",
    "merged_df_cleaned['LatLogger'].fillna(method='ffill', inplace=True)\n",
    "merged_df_cleaned['LongLogger'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Agrupar por segundos\n",
    "grouped = merged_df_cleaned.groupby('Seconds')\n",
    "\n",
    "lat_inter_list = []\n",
    "long_inter_list = []\n",
    "\n",
    "for _, group in grouped:\n",
    "    first_lat = group['LatLogger'].iloc[0]\n",
    "    first_long = group['LongLogger'].iloc[0]\n",
    "    \n",
    "    try:\n",
    "        next_lat = grouped.get_group(_ + 1)['LatLogger'].iloc[0]\n",
    "        next_long = grouped.get_group(_ + 1)['LongLogger'].iloc[0]\n",
    "    except KeyError:\n",
    "        next_lat = first_lat\n",
    "        next_long = first_long\n",
    "    \n",
    "    num_points = len(group)\n",
    "    \n",
    "    if num_points > 1:  # Só interpola se há mais de um ponto no segundo\n",
    "        lat_seq = np.linspace(first_lat, next_lat, num_points + 1)[:-1]\n",
    "        long_seq = np.linspace(first_long, next_long, num_points + 1)[:-1]\n",
    "    else:  # Se só houver um ponto, usa-se o valor existente\n",
    "        lat_seq = [first_lat]\n",
    "        long_seq = [first_long]\n",
    "    \n",
    "    lat_inter_list.extend(lat_seq)\n",
    "    long_inter_list.extend(long_seq)\n",
    "\n",
    "# Atualizar o DataFrame\n",
    "merged_df_cleaned.loc[:, 'LatInter'] = lat_inter_list\n",
    "merged_df_cleaned.loc[:, 'LongInter'] = long_inter_list\n",
    "\n",
    "# Verificar os resultados\n",
    "print(merged_df_cleaned[['RTCHora', 'LatLogger', 'LongLogger', 'SpeedLogger', 'LatInter', 'LongInter']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ea0b26-47ac-4e2b-87c3-d89986248fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o caminho do arquivo de destino\n",
    "caminho_arquivo_csv = 'gpsMergeDataCleanerInter.csv' # Ajuste o caminho conforme necessário\n",
    "# Exportar o DataFrame para um arquivo CSV\n",
    "merged_df_cleaned.to_csv(caminho_arquivo_csv, sep=';', encoding='ISO-8859-1', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa8f47c-3c81-4619-8051-a9918e1701d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
